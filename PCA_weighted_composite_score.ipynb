{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCYjqi4WUODiGRKn7r+fft",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cfsarmiento/GenAI-Research/blob/main/PCA_weighted_composite_score.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute PCA-weighted composite scores\n",
        "\n",
        "I use in here the following approach, as described in the literature. For examples check\n",
        "\n",
        "- [https://www-users.york.ac.uk/~mb55/msc/clinimet/week7/scales.pdf](https://www-users.york.ac.uk/~mb55/msc/clinimet/week7/scales.pdf)\n",
        "-[De Pauw SS, Mervielde I, De Clercq BJ, De Fruyt F, Tremmery S, Deboutte D. Personality symptoms and self-esteem as correlates of psychopathology in child psychiatric patients: Evaluating multiple informant data. Child Psychiatry and Human Development. 2009;40:499–515](https://d1wqtxts1xzle7.cloudfront.net/39504333/Personality_symptoms_and_self-esteem_as_20151028-15947-1tfnqo5-libre.pdf?1446062707=&response-content-disposition=inline%3B+filename%3DPersonality_Symptoms_and_Self_Esteem_as.pdf&Expires=1692921439&Signature=Mml6kL2ZfLAuHN4AXfdNsOP4omTK8ohAuoVknj4tJN7BT~IAzBa8tQH1zcbQIHOXf7N0PEoB8hysuegAbj9PzRd8PgN-MB2~j0koxqkxtalcWlhcflIcsaJhdjVZoZ1ENlxvQRC1Khe4-dtx9dVRKAXYJhtQKL-RK3UPZfAM-EvJsdPvNVusAg2nH822pYdaYNqxVAnGvHtVz1q-DBq07k19w9Sjowgx4C7jqiBkObBDCbzCvQL1naH9Oel83eVyd9OouGSVrEM9MS-WqdnDs0fD7PQa-J9G5mA6zxYB0gguaDuTiChZUYIWo3BjgAXuEz3m8mtbFeDcJFP9ilpHmw__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA)\n",
        "\n",
        "- [Song MK, Lin FC, Ward SE, Fine JP. Composite variables: when and how. Nurs Res. 2013 Jan-Feb;62(1):45-9. doi: 10.1097/NNR.0b013e3182741948. PMID: 23114795; PMCID: PMC5459482.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5459482/)\n",
        "\n",
        "Procedure:\n",
        "- Check the Cronbach-Alplha  reliability coefficient to check the internal consistency of the $K$ Likert-scale variables $x_i$ (all placed in a pandas dataframe).\n",
        "- Normalize each variable, substracting the mean and dividing by the stdev.\n",
        "- Apply PCA, and compute the normalized loadings\n",
        "- Use the normalized loadings as weights to compute the weighted  index:\n",
        "\n",
        "$$comp\\_score_{i}=\\sum_{k=1}^{K}{w_i \\times x_i}$$\n",
        "\n",
        "The class depicted below includes the following methods:\n",
        "\n",
        "- LikertCompositeCalculator( dataframe): this is the instantiation of the class, providing the dataframe with it.\n",
        "- calc_ca() : calculates Cronbach-Alpha from scratch\n",
        "- calc2_ca(): calculates Cronbach-Alpha using pengouin package\n",
        "- calc_composite_score(): reports the composite_socre_vector (same size as the variables $x_i$), and the weight vector (size $K$)\n"
      ],
      "metadata": {
        "id": "Pgn6iw6xrPEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pingouin --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laiuI32PkPbH",
        "outputId": "43c623b1-6fb5-43d0-f7e8-0627530c8e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/198.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.4/198.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.6/198.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LAs0X5uqrJ5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import zscore\n",
        "import pingouin as pg\n",
        "\n",
        "\n",
        "class LikertCompositeCalculator:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def calc_ca(self):\n",
        "        # Calculated manually (checking the package)\n",
        "        k = self.data.shape[1]\n",
        "        variance_sum = self.data.var(axis=0, ddof=1).sum()\n",
        "        total_variance = self.data.sum(axis=1).var(ddof=1)\n",
        "        cronbach_alpha = (k / (k - 1)) * (1 - (variance_sum / total_variance))\n",
        "        return cronbach_alpha\n",
        "\n",
        "    def calc2_ca(self):\n",
        "        # USing pingouin\n",
        "        return pg.cronbach_alpha(self.data)\n",
        "\n",
        "    def calc_composite_score(self):\n",
        "        # Step 2: Standardization\n",
        "        # This is needed for PCA - values are measured in stddevs:  (xi-xi_mean)/xi_sd\n",
        "        standardized_data = zscore(self.data, ddof=1)\n",
        "\n",
        "        # Step 3: Perform PCA\n",
        "        pca = PCA()\n",
        "        pca.fit(standardized_data)\n",
        "\n",
        "        # Step 4: Calculate Weights\n",
        "        weights = pca.components_[0] / np.sum(pca.components_[0])\n",
        "\n",
        "        # Step 5: Calculate Composite Scores\n",
        "        composite_scores = np.dot(standardized_data, weights)\n",
        "\n",
        "        return composite_scores, weights\n"
      ],
      "metadata": {
        "id": "fl7xrTFHm5kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Code to test the class with synthetic data\n",
        "responses = pd.DataFrame({\n",
        "        'x1': [4, 5, 1, 5, 5, 4, 3, 4, 5, 4],\n",
        "        'x2': [3, 5, 2, 5, 4, 4, 4, 4, 4, 3],\n",
        "        'x3': [4, 5, 1, 5, 5, 4, 4, 4, 3, 5],\n",
        "        'x4': [4, 4, 3, 3, 5, 5, 4, 5, 4, 5]\n",
        "    })\n",
        "\n",
        "composite = LikertCompositeCalculator(responses)\n",
        "\n",
        "# Calculate Cronbach's alpha\n",
        "cronbach_alpha = composite.calc_ca()\n",
        "\n",
        "# Calculate Cronbach's alpha\n",
        "cronbach_alpha2 = composite.calc2_ca()\n",
        "\n",
        "# Calculate composite score and weights using PCA\n",
        "composite_scores, weights = composite.calc_composite_score()\n",
        "\n",
        "print(\"Cronbach's Alpha:\", cronbach_alpha)\n",
        "print(\"Cronbach's Alpha:\", cronbach_alpha2)\n",
        "print(\"Composite Scores:\", composite_scores)\n",
        "print(\"Weights:\", weights)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drJy_LXKnoiV",
        "outputId": "670560dd-ac6e-4a20-8ec3-3ef32b13294c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cronbach's Alpha: 0.8246913580246913\n",
            "Cronbach's Alpha: (0.8246913580246915, array([0.539, 0.951]))\n",
            "Composite Scores: [-0.26824542  0.77637853 -2.15439811  0.58579423  0.67930215  0.20999959\n",
            " -0.21666205  0.20999959  0.02226736  0.15556413]\n",
            "Weights: [0.29444015 0.26434194 0.29088298 0.15033493]\n"
          ]
        }
      ]
    }
  ]
}